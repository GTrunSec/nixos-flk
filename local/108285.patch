From 4e5b697ef9ba77e0f8ec7cd2b83b7d0d2e324aa3 Mon Sep 17 00:00:00 2001
From: "Bryan A. S" <bryanasdev000@gmail.com>
Date: Sun, 3 Jan 2021 02:16:51 -0300
Subject: [PATCH 1/3] virtualbox: Include patch for kernel 5.10
 (r0drv-memobj-fix-r0)

It includes one of the necessary patches for the virtualbox to work on the 5.10 (latest) kernel, tested on Vanilla and Zen, 5.10 and 5.9.

In the original issue there are other patches for graphics and shared folders, however, during my tests none of them were necessary, the virtualbox worked perfectly with only the initial patch.

Ref: https://www.virtualbox.org/ticket/20055

Patch: https://www.virtualbox.org/attachment/ticket/20055/linux-5.10-r0drv-memobj-fix-r0.patch

Signed-off-by: Bryan A. S <bryanasdev000@gmail.com>
---
 .../virtualization/virtualbox/default.nix     |  1 +
 .../linux-5.10-r0drv-memobj-fix-r0.patch      | 96 +++++++++++++++++++
 2 files changed, 97 insertions(+)
 create mode 100644 pkgs/applications/virtualization/virtualbox/linux-5.10-r0drv-memobj-fix-r0.patch

diff --git a/pkgs/applications/virtualization/virtualbox/linux-5.10-r0drv-memobj-fix-r0.patch b/pkgs/applications/virtualization/virtualbox/linux-5.10-r0drv-memobj-fix-r0.patch
new file mode 100644
index 0000000000000..516db40e98312
--- /dev/null
+++ b/pkgs/applications/virtualization/virtualbox/linux-5.10-r0drv-memobj-fix-r0.patch
@@ -0,0 +1,96 @@
+Index: src/VBox/Runtime/r0drv/linux/memobj-r0drv-linux.c
+===================================================================
+--- a/src/VBox/Runtime/r0drv/linux/memobj-r0drv-linux.c (Revision 141658)
++++ b/src/VBox/Runtime/r0drv/linux/memobj-r0drv-linux.c (Arbeitskopie)
+@@ -56,9 +56,12 @@
+  * Whether we use alloc_vm_area (3.2+) for executable memory.
+  * This is a must for 5.8+, but we enable it all the way back to 3.2.x for
+  * better W^R compliance (fExecutable flag). */
+-#if RTLNX_VER_MIN(3,2,0) || defined(DOXYGEN_RUNNING)
++#if RTLNX_VER_RANGE(3,2,0, 5,10,0) || defined(DOXYGEN_RUNNING)
+ # define IPRT_USE_ALLOC_VM_AREA_FOR_EXEC
+ #endif
++#if RTLNX_VER_MIN(5,10,0) || defined(DOXYGEN_RUNNING)
++# define IPRT_USE_APPLY_TO_PAGE_RANGE_FOR_EXEC
++#endif
+ 
+ /*
+  * 2.6.29+ kernels don't work with remap_pfn_range() anymore because
+@@ -502,7 +505,43 @@
+ }
+ 
+ 
++#ifdef IPRT_USE_APPLY_TO_PAGE_RANGE_FOR_EXEC
+ /**
++ * User data passed to the apply_to_page_range() callback.
++ */
++typedef struct LNXAPPLYPGRANGE
++{
++    /** Pointer to the memory object. */
++    PRTR0MEMOBJLNX pMemLnx;
++    /** The page protection flags to apply. */
++    pgprot_t       fPg;
++} LNXAPPLYPGRANGE;
++/** Pointer to the user data. */
++typedef LNXAPPLYPGRANGE *PLNXAPPLYPGRANGE;
++/** Pointer to the const user data. */
++typedef const LNXAPPLYPGRANGE *PCLNXAPPLYPGRANGE;
++
++/**
++ * Callback called in apply_to_page_range().
++ *
++ * @returns Linux status code.
++ * @param   pPte                Pointer to the page table entry for the given address.
++ * @param   uAddr               The address to apply the new protection to.
++ * @param   pvUser              The opaque user data.
++ */
++static DECLCALLBACK(int) rtR0MemObjLinuxApplyPageRange(pte_t *pPte, unsigned long uAddr, void *pvUser)
++{
++    PCLNXAPPLYPGRANGE pArgs = (PCLNXAPPLYPGRANGE)pvUser;
++    PRTR0MEMOBJLNX pMemLnx = pArgs->pMemLnx;
++    uint32_t idxPg = (uAddr - (unsigned long)pMemLnx->Core.pv) >> PAGE_SHIFT;
++
++    set_pte(pPte, mk_pte(pMemLnx->apPages[idxPg], pArgs->fPg));
++    return 0;
++}
++#endif
++
++
++/**
+  * Maps the allocation into ring-0.
+  *
+  * This will update the RTR0MEMOBJLNX::Core.pv and RTR0MEMOBJ::fMappedToRing0 members.
+@@ -584,6 +623,11 @@
+         else
+ # endif
+         {
++#  if defined(IPRT_USE_APPLY_TO_PAGE_RANGE_FOR_EXEC)
++            if (fExecutable)
++                pgprot_val(fPg) |= _PAGE_NX; /* Uses RTR0MemObjProtect to clear NX when memory ready, W^X fashion. */
++#  endif
++
+ # ifdef VM_MAP
+             pMemLnx->Core.pv = vmap(&pMemLnx->apPages[0], pMemLnx->cPages, VM_MAP, fPg);
+ # else
+@@ -1851,6 +1895,21 @@
+         preempt_enable();
+         return VINF_SUCCESS;
+     }
++# elif defined(IPRT_USE_APPLY_TO_PAGE_RANGE_FOR_EXEC)
++    PRTR0MEMOBJLNX pMemLnx = (PRTR0MEMOBJLNX)pMem;
++    if (   pMemLnx->fExecutable
++        && pMemLnx->fMappedToRing0)
++    {
++        LNXAPPLYPGRANGE Args;
++        Args.pMemLnx = pMemLnx;
++        Args.fPg = rtR0MemObjLinuxConvertProt(fProt, true /*fKernel*/);
++        int rcLnx = apply_to_page_range(current->active_mm, (unsigned long)pMemLnx->Core.pv + offSub, cbSub,
++                                        rtR0MemObjLinuxApplyPageRange, (void *)&Args);
++        if (rcLnx)
++            return VERR_NOT_SUPPORTED;
++
++        return VINF_SUCCESS;
++    }
+ # endif
+ 
+     NOREF(pMem);

From 63f05c9f9a977198b8a88aa556662aa6ab771bf5 Mon Sep 17 00:00:00 2001
From: "Bryan A. S" <bryanasdev000@gmail.com>
Date: Mon, 18 Jan 2021 12:25:04 -0300
Subject: [PATCH 2/3] virtualbox: Include patch for kernel 5.10 (regops)

Signed-off-by: Bryan A. S <bryanasdev000@gmail.com>
---
 .../virtualization/virtualbox/default.nix     |  1 +
 .../virtualbox/linux-5.10-regops.patch        | 24 +++++++++++++++++++
 2 files changed, 25 insertions(+)
 create mode 100644 pkgs/applications/virtualization/virtualbox/linux-5.10-regops.patch

diff --git a/pkgs/applications/virtualization/virtualbox/linux-5.10-regops.patch b/pkgs/applications/virtualization/virtualbox/linux-5.10-regops.patch
new file mode 100644
index 0000000000000..5c886f41a0b9e
--- /dev/null
+++ b/pkgs/applications/virtualization/virtualbox/linux-5.10-regops.patch
@@ -0,0 +1,24 @@
+Index: trunk/src/VBox/Additions/linux/sharedfolders/regops.c
+===================================================================
+--- a/src/VBox/Additions/linux/sharedfolders/regops.c
++++ b/src/VBox/Additions/linux/sharedfolders/regops.c
+@@ -148,5 +148,9 @@
+         if (paIov->iov_len > 0) {
+             if (access_ok(VERIFY_READ, paIov->iov_base, paIov->iov_len))
++#if RTLNX_VER_MIN(5,10,0)
++                return (uintptr_t)paIov->iov_base >= TASK_SIZE_MAX ? ITER_KVEC : 0;
++#else
+                 return (uintptr_t)paIov->iov_base >= USER_DS.seg ? ITER_KVEC : 0;
++#endif
+             AssertMsgFailed(("%p LB %#zx\n", paIov->iov_base, paIov->iov_len));
+             break;
+@@ -1402,5 +1406,8 @@
+      * Check that this is valid user memory that is actually in the kernel range.
+      */
+-#if RTLNX_VER_MIN(5,0,0) || RTLNX_RHEL_MIN(8,1)
++#if RTLNX_VER_MIN(5,10,0)
++    if (   access_ok((void *)uPtrFrom, cPages << PAGE_SHIFT)
++        && uPtrFrom >= TASK_SIZE_MAX)
++#elif RTLNX_VER_MIN(5,0,0) || RTLNX_RHEL_MIN(8,1)
+     if (   access_ok((void *)uPtrFrom, cPages << PAGE_SHIFT)
+         && uPtrFrom >= USER_DS.seg)

From 2b60ab0fe6b0e28c8df0277cb7ad8683acd354f4 Mon Sep 17 00:00:00 2001
From: "Bryan A. S" <bryanasdev000@gmail.com>
Date: Mon, 18 Jan 2021 22:02:35 -0300
Subject: [PATCH 3/3] virtualbox: Include patch for kernel 5.10 (drm)

Signed-off-by: Bryan A. S <bryanasdev000@gmail.com>
---
 .../virtualbox/linux-5.10-drm.patch           | 300 ++++++++++++++++++
 1 file changed, 300 insertions(+)
 create mode 100644 pkgs/applications/virtualization/virtualbox/linux-5.10-drm.patch

diff --git a/pkgs/applications/virtualization/virtualbox/linux-5.10-drm.patch b/pkgs/applications/virtualization/virtualbox/linux-5.10-drm.patch
new file mode 100644
index 0000000000000..e5a06276b1ad3
--- /dev/null
+++ b/pkgs/applications/virtualization/virtualbox/linux-5.10-drm.patch
@@ -0,0 +1,300 @@
+diff --git a/trunk/src/VBox/Additions/linux/drm/vbox_drv.h b/trunk/src/VBox/Additions/linux/drm/vbox_drv.h
+index 8c85371749..7937f2f2d2 100644
+--- a/src/VBox/Additions/linux/drm/vbox_drv.h
++++ b/src/VBox/Additions/linux/drm/vbox_drv.h
+@@ -175,6 +175,9 @@
+ #include <drm/ttm/ttm_placement.h>
+ #include <drm/ttm/ttm_memory.h>
+ #include <drm/ttm/ttm_module.h>
++#if RTLNX_VER_MIN(5,10,0)
++# include <drm/ttm/ttm_resource.h>
++#endif
+ 
+ #include "vboxvideo_guest.h"
+ #include "vboxvideo_vbe.h"
+@@ -444,7 +447,10 @@ int vbox_bo_create(struct drm_device *dev, int size, int align,
+ int vbox_gem_create(struct drm_device *dev,
+ 		    u32 size, bool iskernel, struct drm_gem_object **obj);
+ 
+-int vbox_bo_pin(struct vbox_bo *bo, u32 pl_flag, u64 *gpu_addr);
++#define VBOX_MEM_TYPE_VRAM   0x1
++#define VBOX_MEM_TYPE_SYSTEM 0x2
++
++int vbox_bo_pin(struct vbox_bo *bo, u32 mem_type, u64 *gpu_addr);
+ int vbox_bo_unpin(struct vbox_bo *bo);
+ 
+ static inline int vbox_bo_reserve(struct vbox_bo *bo, bool no_wait)
+@@ -469,7 +475,7 @@ static inline void vbox_bo_unreserve(struct vbox_bo *bo)
+ 	ttm_bo_unreserve(&bo->bo);
+ }
+ 
+-void vbox_ttm_placement(struct vbox_bo *bo, int domain);
++void vbox_ttm_placement(struct vbox_bo *bo, u32 mem_type);
+ int vbox_bo_push_sysram(struct vbox_bo *bo);
+ int vbox_mmap(struct file *filp, struct vm_area_struct *vma);
+ 
+diff --git a/trunk/src/VBox/Additions/linux/drm/vbox_fb.c b/trunk/src/VBox/Additions/linux/drm/vbox_fb.c
+index adead98d3d..7182d9da1a 100644
+--- a/src/VBox/Additions/linux/drm/vbox_fb.c
++++ b/src/VBox/Additions/linux/drm/vbox_fb.c
+@@ -295,7 +295,7 @@ static int vboxfb_create(struct drm_fb_helper *helper,
+ 	if (ret)
+ 		return ret;
+ 
+-	ret = vbox_bo_pin(bo, TTM_PL_FLAG_VRAM, NULL);
++	ret = vbox_bo_pin(bo, VBOX_MEM_TYPE_VRAM, NULL);
+ 	if (ret) {
+ 		vbox_bo_unreserve(bo);
+ 		return ret;
+diff --git a/trunk/src/VBox/Additions/linux/drm/vbox_mode.c b/trunk/src/VBox/Additions/linux/drm/vbox_mode.c
+index ce7d135cb6..5557db5ef8 100644
+--- a/src/VBox/Additions/linux/drm/vbox_mode.c
++++ b/src/VBox/Additions/linux/drm/vbox_mode.c
+@@ -227,7 +227,7 @@ static int vbox_crtc_set_base(struct drm_crtc *crtc,
+ 	if (ret)
+ 		return ret;
+ 
+-	ret = vbox_bo_pin(bo, TTM_PL_FLAG_VRAM, &gpu_addr);
++	ret = vbox_bo_pin(bo, VBOX_MEM_TYPE_VRAM, &gpu_addr);
+ 	vbox_bo_unreserve(bo);
+ 	if (ret)
+ 		return ret;
+diff --git a/trunk/src/VBox/Additions/linux/drm/vbox_ttm.c b/trunk/src/VBox/Additions/linux/drm/vbox_ttm.c
+index bf87aabc05..5eac926a42 100644
+--- a/src/VBox/Additions/linux/drm/vbox_ttm.c
++++ b/src/VBox/Additions/linux/drm/vbox_ttm.c
+@@ -41,6 +41,7 @@
+ #define PLACEMENT_FLAGS(placement) ((placement).flags)
+ #endif
+ 
++
+ static inline struct vbox_private *vbox_bdev(struct ttm_bo_device *bd)
+ {
+ 	return container_of(bd, struct vbox_private, ttm.bdev);
+@@ -125,6 +126,7 @@ static bool vbox_ttm_bo_is_vbox_bo(struct ttm_buffer_object *bo)
+ 	return false;
+ }
+ 
++#if RTLNX_VER_MAX(5,10,0)
+ static int
+ vbox_bo_init_mem_type(struct ttm_bo_device *bdev, u32 type,
+ 		      struct ttm_mem_type_manager *man)
+@@ -148,6 +150,7 @@ vbox_bo_init_mem_type(struct ttm_bo_device *bdev, u32 type,
+ 
+ 	return 0;
+ }
++#endif
+ 
+ static void
+ vbox_bo_evict_flags(struct ttm_buffer_object *bo, struct ttm_placement *pl)
+@@ -157,7 +160,7 @@ vbox_bo_evict_flags(struct ttm_buffer_object *bo, struct ttm_placement *pl)
+ 	if (!vbox_ttm_bo_is_vbox_bo(bo))
+ 		return;
+ 
+-	vbox_ttm_placement(vboxbo, TTM_PL_FLAG_SYSTEM);
++	vbox_ttm_placement(vboxbo, VBOX_MEM_TYPE_SYSTEM);
+ 	*pl = vboxbo->placement;
+ }
+ 
+@@ -167,11 +170,12 @@ static int vbox_bo_verify_access(struct ttm_buffer_object *bo,
+ 	return 0;
+ }
+ 
++#if RTLNX_VER_MAX(5,10,0)
+ static int vbox_ttm_io_mem_reserve(struct ttm_bo_device *bdev,
+ 				   struct ttm_mem_reg *mem)
+ {
+-	struct ttm_mem_type_manager *man = &bdev->man[mem->mem_type];
+ 	struct vbox_private *vbox = vbox_bdev(bdev);
++	struct ttm_mem_type_manager *man = &bdev->man[mem->mem_type];
+ 
+ 	mem->bus.addr = NULL;
+ 	mem->bus.offset = 0;
+@@ -194,12 +198,53 @@ static int vbox_ttm_io_mem_reserve(struct ttm_bo_device *bdev,
+ 	}
+ 	return 0;
+ }
++#else
++static int vbox_ttm_io_mem_reserve(struct ttm_bo_device *bdev,
++				   struct ttm_resource *mem)
++{
++	struct vbox_private *vbox = vbox_bdev(bdev);
++	mem->bus.addr = NULL;
++	mem->bus.offset = 0;
++	mem->size = mem->num_pages << PAGE_SHIFT;
++	mem->start = 0;
++	mem->bus.is_iomem = false;
++	switch (mem->mem_type) {
++	case TTM_PL_SYSTEM:
++		/* system memory */
++		return 0;
++	case TTM_PL_VRAM:
++		mem->bus.offset = mem->start << PAGE_SHIFT;
++		mem->start = pci_resource_start(vbox->dev->pdev, 0);
++		mem->bus.is_iomem = true;
++		break;
++	default:
++		return -EINVAL;
++	}
++	return 0;
++}
++#endif
+ 
++
++
++#if RTLNX_VER_MIN(5,10,0)
++static void vbox_ttm_io_mem_free(struct ttm_bo_device *bdev,
++				 struct ttm_resource *mem)
++{
++}
++#else
+ static void vbox_ttm_io_mem_free(struct ttm_bo_device *bdev,
+ 				 struct ttm_mem_reg *mem)
+ {
+ }
++#endif
+ 
++#if RTLNX_VER_MIN(5,10,0)
++static void vbox_ttm_tt_destroy(struct ttm_bo_device *bdev, struct ttm_tt *tt)
++{
++	ttm_tt_fini(tt);
++	kfree(tt);
++}
++#else
+ static void vbox_ttm_backend_destroy(struct ttm_tt *tt)
+ {
+ 	ttm_tt_fini(tt);
+@@ -209,6 +254,7 @@ static void vbox_ttm_backend_destroy(struct ttm_tt *tt)
+ static struct ttm_backend_func vbox_tt_backend_func = {
+ 	.destroy = &vbox_ttm_backend_destroy,
+ };
++#endif
+ 
+ #if RTLNX_VER_MAX(4,17,0) && !RTLNX_RHEL_MAJ_PREREQ(7,6) && !RTLNX_SUSE_MAJ_PREREQ(15,1) && !RTLNX_SUSE_MAJ_PREREQ(12,5)
+ static struct ttm_tt *vbox_ttm_tt_create(struct ttm_bo_device *bdev,
+@@ -226,7 +272,9 @@ static struct ttm_tt *vbox_ttm_tt_create(struct ttm_buffer_object *bo,
+ 	if (!tt)
+ 		return NULL;
+ 
++#if RTLNX_VER_MAX(5,10,0)
+ 	tt->func = &vbox_tt_backend_func;
++#endif
+ #if RTLNX_VER_MAX(4,17,0) && !RTLNX_RHEL_MAJ_PREREQ(7,6) && !RTLNX_SUSE_MAJ_PREREQ(15,1) && !RTLNX_SUSE_MAJ_PREREQ(12,5)
+ 	if (ttm_tt_init(tt, bdev, size, page_flags, dummy_read_page)) {
+ #else
+@@ -261,11 +309,16 @@ static void vbox_ttm_tt_unpopulate(struct ttm_tt *ttm)
+ 
+ static struct ttm_bo_driver vbox_bo_driver = {
+ 	.ttm_tt_create = vbox_ttm_tt_create,
++#if RTLNX_VER_MIN(5,10,0)
++	.ttm_tt_destroy = vbox_ttm_tt_destroy,
++#endif
+ #if RTLNX_VER_MAX(4,17,0)
+ 	.ttm_tt_populate = vbox_ttm_tt_populate,
+ 	.ttm_tt_unpopulate = vbox_ttm_tt_unpopulate,
+ #endif
++#if RTLNX_VER_MAX(5,10,0)
+ 	.init_mem_type = vbox_bo_init_mem_type,
++#endif
+ #if RTLNX_VER_MIN(4,10,0) || RTLNX_RHEL_MAJ_PREREQ(7,4)
+ 	.eviction_valuable = ttm_bo_eviction_valuable,
+ #endif
+@@ -318,8 +371,13 @@ int vbox_mm_init(struct vbox_private *vbox)
+ #endif
+ 	}
+ 
++#if RTLNX_VER_MIN(5,10,0)
++	ret = ttm_range_man_init(bdev, TTM_PL_VRAM, false,
++			     vbox->available_vram_size >> PAGE_SHIFT);
++#else
+ 	ret = ttm_bo_init_mm(bdev, TTM_PL_VRAM,
+ 			     vbox->available_vram_size >> PAGE_SHIFT);
++#endif
+ 	if (ret) {
+ 		DRM_ERROR("Failed ttm VRAM init: %d\n", ret);
+ 		goto err_device_release;
+@@ -359,7 +417,7 @@ void vbox_mm_fini(struct vbox_private *vbox)
+ #endif
+ }
+ 
+-void vbox_ttm_placement(struct vbox_bo *bo, int domain)
++void vbox_ttm_placement(struct vbox_bo *bo, u32 mem_type)
+ {
+ 	u32 c = 0;
+ #if RTLNX_VER_MAX(3,18,0) && !RTLNX_RHEL_MAJ_PREREQ(7,2)
+@@ -372,15 +430,36 @@ void vbox_ttm_placement(struct vbox_bo *bo, int domain)
+ 	bo->placement.placement = bo->placements;
+ 	bo->placement.busy_placement = bo->placements;
+ 
+-	if (domain & TTM_PL_FLAG_VRAM)
++	if (mem_type & VBOX_MEM_TYPE_VRAM) {
++#if RTLNX_VER_MIN(5,10,0)
++		bo->placements[c].mem_type = TTM_PL_VRAM;
++		PLACEMENT_FLAGS(bo->placements[c++]) =
++		    TTM_PL_FLAG_WC | TTM_PL_FLAG_UNCACHED;
++#else
+ 		PLACEMENT_FLAGS(bo->placements[c++]) =
+ 		    TTM_PL_FLAG_WC | TTM_PL_FLAG_UNCACHED | TTM_PL_FLAG_VRAM;
+-	if (domain & TTM_PL_FLAG_SYSTEM)
++#endif
++	}
++	if (mem_type & VBOX_MEM_TYPE_SYSTEM) {
++#if RTLNX_VER_MIN(5,10,0)
++		bo->placements[c].mem_type = TTM_PL_SYSTEM;
++		PLACEMENT_FLAGS(bo->placements[c++]) =
++		    TTM_PL_MASK_CACHING;
++#else
+ 		PLACEMENT_FLAGS(bo->placements[c++]) =
+ 		    TTM_PL_MASK_CACHING | TTM_PL_FLAG_SYSTEM;
+-	if (!c)
++#endif
++	}
++	if (!c) {
++#if RTLNX_VER_MIN(5,10,0)
++		bo->placements[c].mem_type = TTM_PL_SYSTEM;
++		PLACEMENT_FLAGS(bo->placements[c++]) =
++		    TTM_PL_MASK_CACHING;
++#else
+ 		PLACEMENT_FLAGS(bo->placements[c++]) =
+ 		    TTM_PL_MASK_CACHING | TTM_PL_FLAG_SYSTEM;
++#endif
++	}
+ 
+ 	bo->placement.num_placement = c;
+ 	bo->placement.num_busy_placement = c;
+@@ -414,7 +493,7 @@ int vbox_bo_create(struct drm_device *dev, int size, int align,
+ 	vboxbo->bo.bdev->dev_mapping = dev->dev_mapping;
+ #endif
+ 
+-	vbox_ttm_placement(vboxbo, TTM_PL_FLAG_VRAM | TTM_PL_FLAG_SYSTEM);
++	vbox_ttm_placement(vboxbo, VBOX_MEM_TYPE_VRAM | VBOX_MEM_TYPE_SYSTEM);
+ 
+ 	acc_size = ttm_bo_dma_acc_size(&vbox->ttm.bdev, size,
+ 				       sizeof(struct vbox_bo));
+@@ -452,7 +531,7 @@ static inline u64 vbox_bo_gpu_offset(struct vbox_bo *bo)
+ #endif
+ }
+ 
+-int vbox_bo_pin(struct vbox_bo *bo, u32 pl_flag, u64 *gpu_addr)
++int vbox_bo_pin(struct vbox_bo *bo, u32 mem_type, u64 *gpu_addr)
+ {
+ #if RTLNX_VER_MIN(4,16,0) || RTLNX_RHEL_MAJ_PREREQ(7,6) || RTLNX_SUSE_MAJ_PREREQ(15,1) || RTLNX_SUSE_MAJ_PREREQ(12,5)
+ 	struct ttm_operation_ctx ctx = { false, false };
+@@ -467,7 +546,7 @@ int vbox_bo_pin(struct vbox_bo *bo, u32 pl_flag, u64 *gpu_addr)
+ 		return 0;
+ 	}
+ 
+-	vbox_ttm_placement(bo, pl_flag);
++	vbox_ttm_placement(bo, mem_type);
+ 
+ 	for (i = 0; i < bo->placement.num_placement; i++)
+ 		PLACEMENT_FLAGS(bo->placements[i]) |= TTM_PL_FLAG_NO_EVICT;
+@@ -540,7 +619,7 @@ int vbox_bo_push_sysram(struct vbox_bo *bo)
+ 	if (bo->kmap.virtual)
+ 		ttm_bo_kunmap(&bo->kmap);
+ 
+-	vbox_ttm_placement(bo, TTM_PL_FLAG_SYSTEM);
++	vbox_ttm_placement(bo, VBOX_MEM_TYPE_SYSTEM);
+ 
+ 	for (i = 0; i < bo->placement.num_placement; i++)
+ 		PLACEMENT_FLAGS(bo->placements[i]) |= TTM_PL_FLAG_NO_EVICT;
